{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install tensorflow-gpu>=2.0.0 tqdm\n",
    "try:\n",
    "    from checkmate.tf2 import get_keras_model\n",
    "except:\n",
    "   !git clone https://github.com/parasj/checkmate.git\n",
    "   os.chdir('./checkmate')\n",
    "   !pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from checkmate.tf2 import get_keras_model\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkmate getting started guide\n",
    "Checkmate is a system for training large neural neural networks on memory-constrained hardware. State-of-the-art models require\n",
    "increasing amounts of GPU memory. Checkmate traces your TensorFlow application and efficiently reschedules the TF graph so that\n",
    "total memory requirements are under the memory budget of your GPU.\n",
    "\n",
    "In this tutorial, we walk through how to train a computer vision model with a basic application of Checkmate. While this \n",
    "application would likely fit within the limits of most GPUs, it serves to illustrate the mechanics of using Checkmate.\n",
    "\n",
    "## Loading CIFAR10 using keras\n",
    "Checkmate optimizes any TensorFlow 2.0 graph. In this example, we load CIFAR10 as an example. We also use a basic few-layer neural network as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load cifar10 dataset\n",
    "batch_size = 1024\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, y_train = x_train.astype(np.float32), y_train.astype(np.float32)\n",
    "x_test, y_test = x_test.astype(np.float32), y_test.astype(np.float32)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# load TensorFlow model from Keras applications along with loss function and optimizer\n",
    "model = get_keras_model(\"test\", input_shape=x_train[0].shape, num_classes=10)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recompiling the TensorFlow test model using Checkmate\n",
    "Checkmate exposes a convenience function `checkmate.tf2.compile_tf2` that will take a Keras model and return\n",
    "a `tf.Function` that runs a single training iteration over a batch. In order to accurately measure memory\n",
    "consumption per operation, Checkmate needs to know the full size of the inputs to your model. The training\n",
    "dataset usually contains this under `train_ds.element_spec`. Note that `element_spec` will also return the\n",
    "shape of the output, which is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from checkmate.tf2.wrapper import compile_tf2\n",
    "element_spec = train_ds.__iter__().__next__()\n",
    "train_iteration = compile_tf2(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    input_spec=element_spec[0],  # retrieve first element of dataset\n",
    "    label_spec=element_spec[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training the large neural network\n",
    "Checkmate has now recompiled our training function. We can continue to use existing TensorFlow functionality for training neural networks, but we substitute the call to the model with Checkmate's version of the training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    with tqdm(total=x_train.shape[0]) as pbar:\n",
    "        for images, labels in train_ds:\n",
    "            predictions, loss_value = train_iteration(images, labels)\n",
    "            train_loss(loss_value)\n",
    "            train_accuracy(labels, predictions)\n",
    "            pbar.update(images.shape[0])\n",
    "            pbar.set_description('Train epoch {}; loss={:0.4f}, acc={:0.4f}'.format(epoch + 1, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    with tqdm(total=x_test.shape[0]) as pbar:\n",
    "        for images, labels in test_ds:\n",
    "            predictions = model(images)\n",
    "            test_loss_value = loss(labels, predictions)\n",
    "            test_loss(test_loss_value)\n",
    "            test_accuracy(labels, predictions)\n",
    "            pbar.update(images.shape[0])\n",
    "            pbar.set_description('Valid epoch {}, loss={:0.4f}, acc={:0.4f}'.format(epoch + 1, test_loss.result(), test_accuracy.result()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
